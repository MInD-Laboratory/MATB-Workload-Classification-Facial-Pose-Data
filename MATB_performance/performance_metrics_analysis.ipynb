{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9fc6233",
   "metadata": {},
   "source": [
    "# Interactive Performance Metrics Pipeline\n",
    "\n",
    "This notebook demonstrates how to use the refactored performance metric extraction functions from `performance_utils.py` to calculate metrics from MATB data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d30ccd",
   "metadata": {},
   "source": [
    "## 1. Calculate metrics for all participants\n",
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54a27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from performance_utils import sysmon_measures, comms_measures, track_measures, resman_measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9745eeb",
   "metadata": {},
   "source": [
    "Set the data directory and find all the csv files containing the eye gaze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f04a500e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 129 files. Example: ['3105_session01.csv', '3105_session02.csv', '3105_session03.csv']\n"
     ]
    }
   ],
   "source": [
    "# Set the directory containing your eye tracker CSV files\n",
    "\n",
    "# Prompt the user to input the PNAS-MATB folder path\n",
    "directory = input(\"Enter the full path to your PNAS-MATB folder: \")\n",
    "matb_directory = os.path.join(directory, \"matb_outputs\")\n",
    "\n",
    "# List available CSV files\n",
    "matb_files = [f for f in os.listdir(matb_directory) if f.endswith('.csv')]\n",
    "print(f\"Found {len(matb_files)} files. Example: {matb_files[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c69625",
   "metadata": {},
   "source": [
    "Process all files and generate a single dataframe of metrics (accuracy and reaction times) in each window for all participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eee06bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: 3105_session01.csv\n",
      "\n",
      "Processing file: 3105_session02.csv\n",
      "\n",
      "Processing file: 3105_session03.csv\n",
      "\n",
      "Processing file: 3206_session01.csv\n",
      "\n",
      "Processing file: 3206_session02.csv\n",
      "\n",
      "Processing file: 3206_session03.csv\n",
      "\n",
      "Processing file: 3207_session01.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m comms_failure_rate, comms_events, comms_own_events, comms_average_reaction_times \u001b[38;5;241m=\u001b[39m comms_measures(df_event_performace)\n\u001b[0;32m     11\u001b[0m track_failure_rate \u001b[38;5;241m=\u001b[39m track_measures(df_event_performace)\n\u001b[1;32m---> 12\u001b[0m resman_failure_rate \u001b[38;5;241m=\u001b[39m \u001b[43mresman_measures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_event_performace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m n_windows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(sysmon_failure_rate)\n\u001b[0;32m     14\u001b[0m window_starts \u001b[38;5;241m=\u001b[39m [w \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_windows)]\n",
      "File \u001b[1;32md:\\VScode folders\\MATB-Workload-Classification-Facial-Pose-Data\\MATB_performance\\performance_utils.py:150\u001b[0m, in \u001b[0;36mresman_measures\u001b[1;34m(df, window_size, overlap, total_time)\u001b[0m\n\u001b[0;32m    148\u001b[0m window_start \u001b[38;5;241m=\u001b[39m window \u001b[38;5;241m*\u001b[39m step\n\u001b[0;32m    149\u001b[0m window_end \u001b[38;5;241m=\u001b[39m window_start \u001b[38;5;241m+\u001b[39m window_size\n\u001b[1;32m--> 150\u001b[0m total_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df[((df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maddress\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma_in_tolerance\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m|\u001b[39m (\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maddress\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb_in_tolerance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m)) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscenario_time\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mbetween(window_start, window_end))])\n\u001b[0;32m    151\u001b[0m performance_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df[((df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maddress\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma_in_tolerance\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m|\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maddress\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb_in_tolerance\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscenario_time\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mbetween(window_start, window_end))])\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_rows \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32md:\\VScode folders\\MATB-Workload-Classification-Facial-Pose-Data\\.venv\\lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\VScode folders\\MATB-Workload-Classification-Facial-Pose-Data\\.venv\\lib\\site-packages\\pandas\\core\\arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\VScode folders\\MATB-Workload-Classification-Facial-Pose-Data\\.venv\\lib\\site-packages\\pandas\\core\\series.py:6130\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6127\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   6128\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 6130\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32md:\\VScode folders\\MATB-Workload-Classification-Facial-Pose-Data\\.venv\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\VScode folders\\MATB-Workload-Classification-Facial-Pose-Data\\.venv\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:130\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mscalar_compare(x\u001b[38;5;241m.\u001b[39mravel(), y, op)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_metrics_df = pd.DataFrame()\n",
    "for file in matb_files:\n",
    "    df_matb = pd.read_csv(os.path.join(matb_directory, file))\n",
    "    print(f\"\\nProcessing file: {file}\")\n",
    "    partid = file.split('_')[0]\n",
    "    session = file.split('_')[1].replace('session', '').replace('.csv', '')\n",
    "    df_event_performace = df_matb[(df_matb['type'] == 'event') | (df_matb['type'] == 'performance')].copy()\n",
    "    df_event_performace['scenario_time'] = df_event_performace['scenario_time'].astype(float)\n",
    "    sysmon_failure_rate, sysmon_average_reaction_times, _,_ = sysmon_measures(df_event_performace)\n",
    "    comms_failure_rate, comms_events, comms_own_events, comms_average_reaction_times = comms_measures(df_event_performace)\n",
    "    track_failure_rate = track_measures(df_event_performace)\n",
    "    resman_failure_rate = resman_measures(df_event_performace)\n",
    "    n_windows = len(sysmon_failure_rate)\n",
    "    window_starts = [w * 30 for w in range(n_windows)]\n",
    "    window_ends = [start + 60 for start in window_starts]\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'participant_id': partid,\n",
    "        'session_number': session,\n",
    "        'window_index': list(range(n_windows)),\n",
    "        'start_time': window_starts,\n",
    "        'end_time': window_ends,\n",
    "        'sysmon_failure_rate': sysmon_failure_rate,\n",
    "        'sysmon_average_reaction_times': sysmon_average_reaction_times,\n",
    "        'comms_failure_rate': comms_failure_rate,\n",
    "        'comms_events': comms_events,\n",
    "        'comms_own_events': comms_own_events,\n",
    "        'comms_average_reaction_times': comms_average_reaction_times,\n",
    "        'track_failure_rate': track_failure_rate,\n",
    "        'resman_failure_rate': resman_failure_rate\n",
    "    })\n",
    "    all_metrics_df = pd.concat([all_metrics_df, metrics_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84190ee7",
   "metadata": {},
   "source": [
    "Calculate average performace metrics in each window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7b436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df['average_accuracy'] = 100 - (all_metrics_df['sysmon_failure_rate'] + all_metrics_df['comms_failure_rate'] + all_metrics_df['track_failure_rate'] + all_metrics_df['resman_failure_rate']) / 4\n",
    "all_metrics_df['average_reaction_time'] = all_metrics_df[['sysmon_average_reaction_times', 'comms_average_reaction_times']].mean(axis=1)/1000  # Convert to seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f85947",
   "metadata": {},
   "source": [
    "Save data for further analysis. Skip if you want to just get the stats results and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5440a1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all metrics to ..\\rf training data\\performance_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "output_csv = os.path.join('..', 'rf training data', 'performance_metrics.csv')\n",
    "all_metrics_df.to_csv(output_csv, index=False)\n",
    "print(f\"Saved all metrics to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11149a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv = os.path.join('..', 'rf training data', 'performance_metrics.csv')\n",
    "all_metrics_df = pd.read_csv(output_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1334eb78",
   "metadata": {},
   "source": [
    "# 2. Run stats and plot figures using stats_figures utilities\n",
    "Import relevant libraries and set the metrics for analysis (Average accuracy and Reaction time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9d17884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error importing in API mode: ImportError('On Windows, cffi mode \"ANY\" is only \"ABI\".')\n",
      "Trying to import in ABI mode.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # Add parent directory to path\n",
    "from stats_figures import run_rpy2_lmer, barplot_ax\n",
    "import matplotlib.pyplot as plt\n",
    "# Define metrics and labels\n",
    "metrics = [\n",
    "            (\"average_accuracy\", \"Average accuracy (%)\"),\n",
    "            (\"average_reaction_time\", \"Average reaction time (s)\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11512871",
   "metadata": {},
   "source": [
    "Load session info for all participants and add relevant dependent variables to all_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc2e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load session information\n",
    "Session_Info = pd.read_csv(\n",
    "    os.path.join(directory,\"participant_info.csv\")\n",
    ")\n",
    "# Add session_order column to Session_Info\n",
    "if {\"session01\", \"session02\", \"session03\"}.issubset(Session_Info.columns):\n",
    "    Session_Info[\"session_order\"] = (\n",
    "        Session_Info[\"session01\"].str[0] +\n",
    "        Session_Info[\"session02\"].str[0] +\n",
    "        Session_Info[\"session03\"].str[0]\n",
    "    )\n",
    "\n",
    "# Map 'condition' from Session_Info to all_metrics_df using participant_id and session_number\n",
    "def get_condition(row):\n",
    "    pid = int(row['participant_id'])\n",
    "    session_col = f\"session{row['session_number']}\"\n",
    "    if pid in Session_Info[\"Participant ID\"].values and session_col in Session_Info.columns:\n",
    "        cond = Session_Info.loc[Session_Info[\"Participant ID\"] == pid, session_col].values\n",
    "        print(f\"Participant {pid}, Session {row['session_number']}: Condition {cond}\")\n",
    "        if len(cond) > 0:\n",
    "            return cond[0]\n",
    "    return None\n",
    "all_metrics_df[\"condition\"] = all_metrics_df.apply(get_condition, axis=1)\n",
    "# Prepare session_order and session_order_numeric maps\n",
    "session_order_numeric_map = {\"LMH\": 1, \"LHM\": 2}\n",
    "# Map session_order_numeric from Session_Info to all_metrics_df using participant_id\n",
    "if \"session_order\" in Session_Info.columns:\n",
    "    session_info_numeric_map = Session_Info.set_index(\"Participant ID\")[\"session_order\"].map(session_order_numeric_map).to_dict()\n",
    "    all_metrics_df[\"session_order_numeric\"] = all_metrics_df[\"participant_id\"].astype(int).map(session_info_numeric_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3328368",
   "metadata": {},
   "source": [
    "Run stats and make plots for the metrics of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7920591e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Average accuracy (%) ---\n",
      "Means for average_accuracy:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R callback write-console: Error in lme4::lFormula(formula = average_accuracy ~ condition + session_order_numeric +  : \n",
      "  0 (non-NA) cases\n",
      "  \n"
     ]
    },
    {
     "ename": "RRuntimeError",
     "evalue": "Error in lme4::lFormula(formula = average_accuracy ~ condition + session_order_numeric +  : \n  0 (non-NA) cases\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Run mixed effects model and get stats\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m pairwise_p, means, cis \u001b[38;5;241m=\u001b[39m \u001b[43mrun_rpy2_lmer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_metrics_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Prepare data for plotting\u001b[39;00m\n\u001b[0;32m     10\u001b[0m conds \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\VScode folders\\MATB-Workload-Classification-Facial-Pose-Data\\MATB_performance\\..\\stats_figures.py:54\u001b[0m, in \u001b[0;36mrun_rpy2_lmer\u001b[1;34m(df, dv, feature_label)\u001b[0m\n\u001b[0;32m     52\u001b[0m robjects\u001b[38;5;241m.\u001b[39mr(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibrary(lmerTest)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m robjects\u001b[38;5;241m.\u001b[39mr(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibrary(emmeans)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 54\u001b[0m \u001b[43mrobjects\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel <- lmer(\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mformula\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, data=dat)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (R lmerTest) ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     56\u001b[0m summary \u001b[38;5;241m=\u001b[39m robjects\u001b[38;5;241m.\u001b[39mr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary(model)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\VScode folders\\MATB-Workload-Classification-Facial-Pose-Data\\.venv\\lib\\site-packages\\rpy2\\robjects\\__init__.py:552\u001b[0m, in \u001b[0;36mR.__call__\u001b[1;34m(self, string, invisible, print_r_warnings)\u001b[0m\n\u001b[0;32m    550\u001b[0m     invisible \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invisible\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m invisible:\n\u001b[1;32m--> 552\u001b[0m     res, visible \u001b[38;5;241m=\u001b[39m \u001b[43mrinterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevalr_expr_with_visible\u001b[49m\u001b[43m(\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mr_expr\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m visible[\u001b[38;5;241m0\u001b[39m]:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    556\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\VScode folders\\MATB-Workload-Classification-Facial-Pose-Data\\.venv\\lib\\site-packages\\rpy2\\rinterface\\__init__.py:205\u001b[0m, in \u001b[0;36mevalr_expr_with_visible\u001b[1;34m(expr, envir)\u001b[0m\n\u001b[0;32m    198\u001b[0m r_res \u001b[38;5;241m=\u001b[39m rmemory\u001b[38;5;241m.\u001b[39mprotect(\n\u001b[0;32m    199\u001b[0m         openrlib\u001b[38;5;241m.\u001b[39mrlib\u001b[38;5;241m.\u001b[39mR_tryEval(\n\u001b[0;32m    200\u001b[0m             r_call,\n\u001b[0;32m    201\u001b[0m             envir\u001b[38;5;241m.\u001b[39m__sexp__\u001b[38;5;241m.\u001b[39m_cdata,  \u001b[38;5;66;03m# call context.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m             error_occured)\n\u001b[0;32m    203\u001b[0m )\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_occured[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m embedded\u001b[38;5;241m.\u001b[39mRRuntimeError(_rinterface\u001b[38;5;241m.\u001b[39m_geterrmessage())\n\u001b[0;32m    206\u001b[0m res \u001b[38;5;241m=\u001b[39m conversion\u001b[38;5;241m.\u001b[39m_cdata_to_rinterface(r_res)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, ListSexpVector)\n",
      "\u001b[1;31mRRuntimeError\u001b[0m: Error in lme4::lFormula(formula = average_accuracy ~ condition + session_order_numeric +  : \n  0 (non-NA) cases\n"
     ]
    }
   ],
   "source": [
    "# Use the all_metrics_df from previous cell\n",
    "if 'all_metrics_df' in locals():\n",
    "    for metric, label in metrics:\n",
    "        print(f\"\\n--- {label} ---\")\n",
    "        # Run mixed effects model and get stats\n",
    "        pairwise_p, means, cis = run_rpy2_lmer(\n",
    "            all_metrics_df, metric, label\n",
    "        )\n",
    "        # Prepare data for plotting\n",
    "        conds = [\"L\", \"M\", \"H\"]\n",
    "        mean_vals = [means.get(c, float('nan')) for c in conds]\n",
    "        sems = [(cis[c][1] - cis[c][0]) / 3.92 if c in cis else float('nan') for c in conds]  # 95% CI to SEM\n",
    "        pvals = [pairwise_p.get((\"L\", \"M\"), 1.0), pairwise_p.get((\"L\", \"H\"), 1.0), pairwise_p.get((\"M\", \"H\"), 1.0)]\n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(4, 5))\n",
    "        barplot_ax(ax, mean_vals, sems, pvals, ylabel=label, metric_name=metric)\n",
    "        ax.set_title(label, fontsize=13, weight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"all_metrics_df not found. Please run the previous cell to generate metrics.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
