{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9fc6233",
   "metadata": {},
   "source": [
    "# Interactive Performance Metrics Pipeline\n",
    "\n",
    "This notebook demonstrates how to use the refactored performance metric extraction functions from `performance_utils.py` to calculate metrics from MATB data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d30ccd",
   "metadata": {},
   "source": [
    "## 1. Calculate metrics for all participants\n",
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54a27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from performance_utils import sysmon_measures, comms_measures, track_measures, resman_measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9745eeb",
   "metadata": {},
   "source": [
    "Set the data directory and find all the csv files containing the eye gaze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04a500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory containing your eye tracker CSV files\n",
    "\n",
    "# Prompt the user to input the PNAS-MATB folder path\n",
    "directory = input(\"Enter the full path to your PNAS-MATB folder: \")\n",
    "matb_directory = os.path.join(directory, \"matb_outputs\")\n",
    "\n",
    "# List available CSV files\n",
    "matb_files = [f for f in os.listdir(matb_directory) if f.endswith('.csv')]\n",
    "print(f\"Found {len(matb_files)} files. Example: {matb_files[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c69625",
   "metadata": {},
   "source": [
    "Process all files and generate a single dataframe of metrics (accuracy and reaction times) in each window for all participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee06bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df = pd.DataFrame()\n",
    "for file in matb_files:\n",
    "    df_matb = pd.read_csv(os.path.join(matb_directory, file))\n",
    "    print(f\"\\nProcessing file: {file}\")\n",
    "    partid = file.split('_')[0]\n",
    "    session = file.split('_')[1].replace('session', '').replace('.csv', '')\n",
    "    df_event_performace = df_matb[(df_matb['type'] == 'event') | (df_matb['type'] == 'performance')].copy()\n",
    "    df_event_performace['scenario_time'] = df_event_performace['scenario_time'].astype(float)\n",
    "    sysmon_failure_rate, sysmon_average_reaction_times, _,_ = sysmon_measures(df_event_performace)\n",
    "    comms_failure_rate, comms_events, comms_own_events, comms_average_reaction_times = comms_measures(df_event_performace)\n",
    "    track_failure_rate = track_measures(df_event_performace)\n",
    "    resman_failure_rate = resman_measures(df_event_performace)\n",
    "    n_windows = len(sysmon_failure_rate)\n",
    "    window_starts = [w * 30 for w in range(n_windows)]\n",
    "    window_ends = [start + 60 for start in window_starts]\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'participant_id': partid,\n",
    "        'session_number': session,\n",
    "        'window_index': list(range(n_windows)),\n",
    "        'start_time': window_starts,\n",
    "        'end_time': window_ends,\n",
    "        'sysmon_failure_rate': sysmon_failure_rate,\n",
    "        'sysmon_average_reaction_times': sysmon_average_reaction_times,\n",
    "        'comms_failure_rate': comms_failure_rate,\n",
    "        'comms_events': comms_events,\n",
    "        'comms_own_events': comms_own_events,\n",
    "        'comms_average_reaction_times': comms_average_reaction_times,\n",
    "        'track_failure_rate': track_failure_rate,\n",
    "        'resman_failure_rate': resman_failure_rate\n",
    "    })\n",
    "    all_metrics_df = pd.concat([all_metrics_df, metrics_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84190ee7",
   "metadata": {},
   "source": [
    "Calculate average performace metrics in each window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7b436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df['average_accuracy'] = 100 - (all_metrics_df['sysmon_failure_rate'] + all_metrics_df['comms_failure_rate'] + all_metrics_df['track_failure_rate'] + all_metrics_df['resman_failure_rate']) / 4\n",
    "all_metrics_df['average_reaction_time'] = all_metrics_df[['sysmon_average_reaction_times', 'comms_average_reaction_times']].mean(axis=1)/1000  # Convert to seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f85947",
   "metadata": {},
   "source": [
    "Save data for further analysis. Skip if you want to just get the stats results and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5440a1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv = os.path.join('..', 'rf training data', 'performance_metrics.csv')\n",
    "all_metrics_df.to_csv(output_csv, index=False)\n",
    "print(f\"Saved all metrics to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d17884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # Add parent directory\n",
    "from stats_figures import run_rpy2_lmer, barplot_ax\n",
    "import matplotlib.pyplot as plt\n",
    "# Define metrics and labels\n",
    "metrics = [\n",
    "            (\"average_accuracy\", \"Average accuracy (%)\"),\n",
    "            (\"average_reaction_time\", \"Average reaction time (s)\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc2e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load session information\n",
    "Session_Info = pd.read_csv(\n",
    "    os.path.join(directory,\"participant_info.csv\")\n",
    ")\n",
    "# Add session_order column to Session_Info\n",
    "if {\"session01\", \"session02\", \"session03\"}.issubset(Session_Info.columns):\n",
    "    Session_Info[\"session_order\"] = (\n",
    "        Session_Info[\"session01\"].str[0] +\n",
    "        Session_Info[\"session02\"].str[0] +\n",
    "        Session_Info[\"session03\"].str[0]\n",
    "    )\n",
    "\n",
    "# Map 'condition' from Session_Info to all_metrics_df using participant_id and session_number\n",
    "def get_condition(row):\n",
    "    pid = int(row['participant_id'])\n",
    "    session_col = f\"session{row['session_number']}\"\n",
    "    if pid in Session_Info[\"Participant ID\"].values and session_col in Session_Info.columns:\n",
    "        cond = Session_Info.loc[Session_Info[\"Participant ID\"] == pid, session_col].values\n",
    "        if len(cond) > 0:\n",
    "            return cond[0]\n",
    "    return None\n",
    "all_metrics_df[\"condition\"] = all_metrics_df.apply(get_condition, axis=1)\n",
    "# Prepare session_order and session_order_numeric maps\n",
    "session_order_numeric_map = {\"LMH\": 1, \"LHM\": 2}\n",
    "# Map session_order_numeric from Session_Info to all_metrics_df using participant_id\n",
    "if \"session_order\" in Session_Info.columns:\n",
    "    session_info_numeric_map = Session_Info.set_index(\"Participant ID\")[\"session_order\"].map(session_order_numeric_map).to_dict()\n",
    "    all_metrics_df[\"session_order_numeric\"] = all_metrics_df[\"participant_id\"].astype(int).map(session_info_numeric_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7920591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the all_metrics_df from previous cell\n",
    "if 'all_metrics_df' in locals():\n",
    "    for metric, label in metrics:\n",
    "        print(f\"\\n--- {label} ---\")\n",
    "        # Run mixed effects model and get stats\n",
    "        pairwise_p, means, cis = run_rpy2_lmer(\n",
    "            all_metrics_df, metric, label\n",
    "        )\n",
    "        # Prepare data for plotting\n",
    "        conds = [\"L\", \"M\", \"H\"]\n",
    "        mean_vals = [means.get(c, float('nan')) for c in conds]\n",
    "        sems = [(cis[c][1] - cis[c][0]) / 3.92 if c in cis else float('nan') for c in conds]  # 95% CI to SEM\n",
    "        pvals = [pairwise_p.get((\"L\", \"M\"), 1.0), pairwise_p.get((\"L\", \"H\"), 1.0), pairwise_p.get((\"M\", \"H\"), 1.0)]\n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(4, 5))\n",
    "        barplot_ax(ax, mean_vals, sems, pvals, ylabel=label, metric_name=metric)\n",
    "        ax.set_title(label, fontsize=13, weight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"all_metrics_df not found. Please run the previous cell to generate metrics.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
